{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 12 Problem 3\n",
    "\n",
    "If you are not using the `Assignments` tab on the course JupyterHub server to read this notebook, read [Activating the assignments tab](https://github.com/lcdm-uiuc/info490-sp17/blob/master/help/act_assign_tab.md).\n",
    "\n",
    "A few things you should keep in mind when working on assignments:\n",
    "\n",
    "1. Make sure you fill in any place that says `YOUR CODE HERE`. Do **not** write your answer in anywhere else other than where it says `YOUR CODE HERE`. Anything you write anywhere else will be removed or overwritten by the autograder.\n",
    "\n",
    "2. Before you submit your assignment, make sure everything runs as expected. Go to menubar, select _Kernel_, and restart the kernel and run all cells (_Restart & Run all_).\n",
    "\n",
    "3. Do not change the title (i.e. file name) of this notebook.\n",
    "\n",
    "4. Make sure that you save your work (in the menubar, select _File_  â†’ _Save and CheckPoint_)\n",
    "\n",
    "5. You are allowed to submit an assignment multiple times, but only the most recent submission will be graded.\n",
    "-----\n",
    "# Problem 12.3. Apache Pig\n",
    "\n",
    "In this problem, we will run Pig to compute the average rating for each book in the book-crossing data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "6d15b700bc7aa54029fbbed9c6f1d112",
     "grade": false,
     "grade_id": "imports",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from nose.tools import assert_equal, assert_almost_equal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Raw Data Preview\n",
    "\n",
    "First, let's have a look at the data in case you don't remember them from w6p1 assignment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "a2eae12f6775bc02bb6624c8574cf66d",
     "grade": false,
     "grade_id": "h1",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "!head -5 $HOME/data/book-crossing/BX-Book-Ratings.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "380e149411129856484db1734d03a1ef",
     "grade": false,
     "grade_id": "h2",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "!head -5 $HOME/data/book-crossing/BX-Books.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Data Preprocessing\n",
    "To make the messy data easier to be processed later, the bash script here does the following:\n",
    "- Removes the header line;\n",
    "- Removes the quotation marks for data in each field (otherwise there might be problems with numbers);\n",
    "- Cut the last three columns of `BX-Books.csv`, which are image urls and publishers that we don't need for this problem;\n",
    "- Saves the output as `ratings.csv`, `books.csv` to the current directory (same directory as this notebook);\n",
    "- Displays the first 10 lines of each output csv file.\n",
    "\n",
    "The columns in the processed file is:\n",
    "- Columns of ratings.csv: **User-ID; ISBN; Book-Rating**\n",
    "- Columns of books.csv: **ISBN; Book-Title; Book-Author; Year-Of-Publication**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "4a7a49cfbfc4a1c9f93c200fe3f372b9",
     "grade": false,
     "grade_id": "pro",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "sed 's/\"//g' $HOME/data/book-crossing/BX-Book-Ratings.csv | sed '1d' > ratings.csv\n",
    "sed 's/\"//g' $HOME/data/book-crossing/BX-Books.csv | cut -d';' -f -4 | sed '1d' > books.csv\n",
    "\n",
    "echo\n",
    "echo '***** Ratings File *****'\n",
    "head ratings.csv\n",
    "\n",
    "echo\n",
    "echo '***** Books File *****'\n",
    "head books.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Pig Latin: Average\n",
    "\n",
    "Write a Pig script that:\n",
    "\n",
    "- Imports `ratings.csv` and `books.csv` (note that these two files are seperated by semicolon),\n",
    "- Groups all reviews by ISBN and uses [AVG](https://pig.apache.org/docs/r0.7.0/piglatin_ref2.html#AVG) to compute the average rating for each book,\n",
    "- Joins the averaged rating dataset and the book dataset on the ISBN column, \n",
    "- Sorts the joined dataset by book title using default ascending string order, and\n",
    "- Uses the DUMP command to display the first 10 rows.\n",
    "\n",
    "The resulting schema should contain six columns:\n",
    "\n",
    "```\n",
    "(ISBN and average rating from calculated ratings.csv, ISBN, book title, book author, publish year from books.csv)\n",
    "```\n",
    "\n",
    "For example, the second line should be (the first line is harder to read since its title has commas):\n",
    "\n",
    "```\n",
    "(0964147726,0.0,0964147726, Always Have Popsicles,Rebecca Harvin,1994)\n",
    "```\n",
    "\n",
    "Some hints for debugging:\n",
    "\n",
    "- Don't rush to the end; do and check one step at a time.\n",
    "- Use operations that display output wisely, e.g. DESCRIBE, ILLUSTRATE.\n",
    "- Before you use DUMP, make sure that you are trying to display a small number of rows, instead of all rows at a time. Otherwise your notebook might crash.\n",
    "- Take advantage of the debugging cell provided before the assertion cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "6600e7ec94041f80c723cbbb21c0845e",
     "grade": false,
     "grade_id": "avg",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "%%writefile average.pig\n",
    "\n",
    "--YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "3179db338492faf491941c1ff1b359e7",
     "grade": false,
     "grade_id": "print",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "average_ratings = !pig -x local -f average.pig 2> pig_stderr.log\n",
    "print('\\n'.join(average_ratings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To debug, uncomment and run the following code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "d797a9b4c492229b61c5e527606f6235",
     "grade": false,
     "grade_id": "debug",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#!cat pig_stderr.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "e4cc412068446224b8a78ae61f43a4a6",
     "grade": true,
     "grade_id": "test",
     "locked": true,
     "points": 40,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "answer = [\n",
    "    '(0590567330,2.25,0590567330, A Light in the Storm: The Civil War Diary of Amelia Martin, Fenwick Island, Delaware, 1861 (Dear America),Karen Hesse,1999)',\n",
    "    '(0964147726,0.0,0964147726, Always Have Popsicles,Rebecca Harvin,1994)',\n",
    "    '(0942320093,0.0,0942320093, Apple Magic (The Collector\\'s series),Martina Boudreau,1984)',\n",
    "    '(0310232546,8.0,0310232546, Ask Lily (Young Women of Faith: Lily Series, Book 5),Nancy N. Rue,2001)',\n",
    "    '(0962295701,0.0,0962295701, Beyond IBM: Leadership Marketing and Finance for the 1990s,Lou Mobley,1989)',\n",
    "    '(0439188970,0.0,0439188970, Clifford Visita El Hospital (Clifford El Gran Perro Colorado),Norman Bridwell,2000)',\n",
    "    '(0399151788,10.0,0399151788, Dark Justice,Jack Higgins,2004)',\n",
    "    '(0786000015,0.0,0786000015, Deceived,Carla Simpson,1994)',\n",
    "    '(006250746X,5.0,006250746X, Earth Prayers From around the World: 365 Prayers, Poems, and Invocations for Honoring the Earth,Elizabeth Roberts,1991)',\n",
    "    '(1566869250,5.0,1566869250, Final Fantasy Anthology: Official Strategy Guide (Brady Games),David Cassady,1999)'\n",
    "    ]\n",
    "\n",
    "a1 = [a.split(',') for a in answer]\n",
    "a2 = [a.split(',') for a in average_ratings]\n",
    "\n",
    "for irow, row in enumerate(answer):\n",
    "    for icol in [0, 2, 3]:\n",
    "        assert_equal(a1[irow][icol], a2[irow][icol])\n",
    "    #float numbers in column 1\n",
    "    assert_almost_equal(float(a1[irow][1]), float(a2[irow][1]))\n",
    "    if irow in [0, 3, 8]: \n",
    "        continue\n",
    "    for icol in [4, 5]:\n",
    "        assert_equal(a1[irow][icol], a2[irow][icol])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "103384acc4c25019274bca59e62ab153",
     "grade": false,
     "grade_id": "rm",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Remove pig log files\n",
    "rm -f pig*.log\n",
    "\n",
    "# Remove our pig scripts\n",
    "rm -f *.pig\n",
    "\n",
    "# Remove csv files\n",
    "rm books.csv ratings.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

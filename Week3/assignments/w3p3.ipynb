{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "92f305b94c8cc1e3d3a098fd807fdfa5",
     "grade": false,
     "grade_id": "header",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Week 2 Problem 3\n",
    "\n",
    "If you are not using the `Assignments` tab on the course JupyterHub server to read this notebook, read [Activating the assignments tab](https://github.com/lcdm-uiuc/info490-sp17/blob/master/help/act_assign_tab.md).\n",
    "\n",
    "A few things you should keep in mind when working on assignments:\n",
    "\n",
    "1. Make sure you fill in any place that says `YOUR CODE HERE`. Do **not** write your answer in anywhere else other than where it says `YOUR CODE HERE`. Anything you write anywhere else will be removed or overwritten by the autograder.\n",
    "\n",
    "2. Before you submit your assignment, make sure everything runs as expected. Go to menubar, select _Kernel_, and restart the kernel and run all cells (_Restart & Run all_).\n",
    "\n",
    "3. Do not change the title (i.e. file name) of this notebook.\n",
    "\n",
    "4. Make sure that you save your work (in the menubar, select _File_  â†’ _Save and CheckPoint_)\n",
    "\n",
    "5. You are allowed to submit an assignment multiple times, but only the most recent submission will be graded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3.3. Supervised Learning: Naive Bayes\n",
    "\n",
    "In this problem, we will implement Naive Bayes from scratch using **Numpy**. You are free to use numpy functions or explicit math functions for this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "0de4836cf0bbbb2b7823f54a7525b28c",
     "grade": false,
     "grade_id": "import",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.testing import assert_array_equal, assert_array_almost_equal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate Data by Class\n",
    "\n",
    "Write a function that takes two Numpy arrays, separates data by class value, and returns the result as a dictionary. The keys of the dictionary are class values, and the dictionary values are the rows in `X` that correspond to each class value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "055587bfad6305258d09eab22eeda0d0",
     "grade": false,
     "grade_id": "separate_by_class_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def separate_by_class(X, y):\n",
    "    '''\n",
    "    Separate the training set (\"X\") by class value (\"y\")\n",
    "    so that we can calculate statistics for each class.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X: A 2d numpy array\n",
    "    y: A 1d numpy array\n",
    "    Returns\n",
    "    -------\n",
    "    A dictionary of 2d numpy arrays\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    return separated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "ca1abc0aaac655ce58b016e7bbbf817f",
     "grade": true,
     "grade_id": "separate_by_class_test",
     "locked": true,
     "points": 4,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "X_t = np.array( [[2, 21], [1, 20], [3, 22]] )\n",
    "y_t = np.array( [1, 0, 1] )\n",
    "separated_t = separate_by_class(X_t, y_t)\n",
    "assert_array_equal(separated_t[0], np.array( [ [1, 20] ] ))\n",
    "assert_array_equal(separated_t[1], np.array( [ [2, 21], [3, 22] ] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Mean\n",
    "\n",
    "We calculate the mean and use it as the middle of our gaussian distribution when calculating probabilities. If the input array is a 2d array (i.e., a matrix), you should take the mean of each **column**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "eb9a4a4b05adf43b07c6828a180ecae8",
     "grade": false,
     "grade_id": "calculate_mean_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def calculate_mean(array):\n",
    "    '''\n",
    "    Calculates the mean of each column, i.e. each attribute.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    A 1d or 2d numpy array\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A 1d or 2d numpy array\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "b162d81df855deff9efa1d8d856387f1",
     "grade": true,
     "grade_id": "calculate_mean_test",
     "locked": true,
     "points": 4,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "array_t = np.array( [ [1, 4, 7], [2, 5, 6], [3, 6, 8] ] )\n",
    "mean_t = calculate_mean(array_t)\n",
    "assert_array_equal(mean_t, np.array( [2., 5., 7.] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Standard Deviation\n",
    "\n",
    "Write a function that calculates the standard deviation of each **column** using the **N-1** method. The input array can be a 2d array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "6011c48d0b567e6c1a535a4115441215",
     "grade": false,
     "grade_id": "calculate_stdev_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def calculate_stdev(array):\n",
    "    '''\n",
    "    Calculates the standard deviation (N-1 method) of each column, i.e. each attribute.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A 1d or 2d numpy array\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A 1d or 2d numpy array\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    return stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "fe77fa84fb1b8b079f5282eae4b227bd",
     "grade": true,
     "grade_id": "calculate_stdev_test",
     "locked": true,
     "points": 4,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "array_t = np.array( [ [1, 20, 14], [2, 21, 15], [3, 22, 16] ] )\n",
    "stdev_t = calculate_stdev(array_t)\n",
    "assert_array_equal(stdev_t, np.array( [1., 1., 1.] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize Data Set\n",
    "\n",
    "For a given list of instances (for a class value), we calculate the mean and the standard deviation for each attribute. The output is a numpy array of tuples of (mean, standard deviation) pairs for each attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "5d15c92a8ba7eee5018d94d42b2f0bb3",
     "grade": false,
     "grade_id": "summarize_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def summarize(X):\n",
    "    '''\n",
    "    For a given list of instances (for a class value),\n",
    "    calculates the mean and the standard deviation for each attribute.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    A 2d numpy array\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A 2d numpy array\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "56ea6c96b00890d1e1aa1ac74762964d",
     "grade": true,
     "grade_id": "summarize_test",
     "locked": true,
     "points": 4,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "X_t = np.array( [ [1, 20], [2, 21], [3, 22] ] )\n",
    "summary_t = summarize(X_t)\n",
    "assert_array_equal(summary_t, np.array( [ (2.0, 1.0), (21.0, 1.0) ] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize Attributes By Class\n",
    "\n",
    "We calculate the summaries for each attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "644bb36a4899639d62fdf83dd2fd9afd",
     "grade": false,
     "grade_id": "summarize_by_class_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def summarize_by_class(X, y):\n",
    "    '''\n",
    "    Separates a training set into instances grouped by class.\n",
    "    It then calculates the summaries for each attribute.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X: A 2d numpy array. Represents training attributes.\n",
    "    y: A 1d numpy array. Represents class labels.\n",
    "    Returns\n",
    "    -------\n",
    "    A dictionary of 2d numpy arrays. Uses each class label as keys\n",
    "    and summary for each class label as values.\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "c789211fbdb5337e7c269467bc313020",
     "grade": true,
     "grade_id": "summarize_by_class_test",
     "locked": true,
     "points": 4,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "X_t = np.array( [ [1, 20], [2, 21], [3, 22], [4, 22] ] )\n",
    "y_t = np.array( [1, 0, 1, 0] )\n",
    "summaries_t = summarize_by_class(X_t, y_t)\n",
    "assert_array_almost_equal(summaries_t[0], np.array( [ (3., 1.41421356), (21.5, 0.70710678) ] ))\n",
    "assert_array_almost_equal(summaries_t[1], np.array( [ (2., 1.41421356), (21.0, 1.41421356) ] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Log of Gaussian Probability Density Function\n",
    "\n",
    "Calculate the **log** of a Gaussian Probability Density Function. The conditional probabilities for each class given an attribute value are small. When they are multiplied together they result in very small values, which can lead to floating point underflow (numbers too small to represent in Python). A common fix for this is to combine the log of the probabilities together. If the input arguments are 1d arrays, the output should be a 1d array as well, and the n-th element in the output array is the log probability calculated using n-th elements of the input arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "4e2d9f708195ea9e680738acd64675f8",
     "grade": false,
     "grade_id": "calculate_log_probability_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def calculate_log_probability(x, mean, stdev):\n",
    "    '''\n",
    "    Calculates log of Gaussian function to estimate\n",
    "    the log probability of a given attribute value.\n",
    "    Assume x, mean, stdev have the same length.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x: A float or 1d numpy array\n",
    "    mean: A float or 1d numpy array\n",
    "    stdev: A float or 1d numpy array\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A float or 1d numpy array\n",
    "    '''\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    return log_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "b59708ffc5f120318c4a3c160b727a00",
     "grade": true,
     "grade_id": "calculate_log_probability_test",
     "locked": true,
     "points": 4,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "array_t = calculate_log_probability(np.array( [71.5] ), np.array( [73] ), np.array( [6.2] ))\n",
    "assert_array_almost_equal(array_t, np.array( [ -2.7727542144336588 ] ))\n",
    "\n",
    "array_t2 = calculate_log_probability(np.array( [1, 2] ), np.array( [3, 4] ), np.array( [5, 6] ))\n",
    "assert_array_almost_equal(array_t2, np.array( [-2.60837645, -2.76625356] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Class Probabilities\n",
    "\n",
    "Remember that you calculated **log** of probabilities. Therefore, instead of combine probabilities together by multiplying them, you should **add** the log of probabilities. If the input array has more than one instance, for each instance you should have a summed log probability of attributes for each class value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "a80e19b527c7685a1ab5e693d4970d49",
     "grade": false,
     "grade_id": "calculate_class_log_probabilities_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def calculate_class_log_probabilities(summaries, input_array):\n",
    "    '''\n",
    "    Combines the probabilities of all of the attribute values for a data instance\n",
    "    and comes up with a probability of the entire data instance belonging to the class.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    summaries: A dictionary of 2d numpy arrays\n",
    "    input_array: A numpy array of instances; each instance is a numpy array of attributes\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A dictionary of 1d numpy arrays of summed log probabilities\n",
    "    '''\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    return log_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "2c0a1d774a51346bdce5a95bff6d117d",
     "grade": true,
     "grade_id": "calculate_class_log_probabilities_test",
     "locked": true,
     "points": 8,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "summaries_t = {0: np.array( [ (1, 0.5) ]), 1: np.array( [ (20, 5.0) ] )}\n",
    "input_t = np.array( [[1.1]] )\n",
    "log_probabilities = calculate_class_log_probabilities(summaries_t, input_t)\n",
    "assert_array_almost_equal(log_probabilities[0], np.array( [-0.24579135264472743] ))\n",
    "assert_array_almost_equal(log_probabilities[1], np.array( [-9.6725764456387715] ))\n",
    "\n",
    "input_t2 = np.array( [[4], [.9], [0]] )\n",
    "log_probabilities2 = calculate_class_log_probabilities(summaries_t, input_t2)\n",
    "assert_array_almost_equal(log_probabilities2[0], np.array( [-18.225791352644727, -0.24579135264472729, -2.2257913526447273] ))\n",
    "assert_array_almost_equal(log_probabilities2[1], np.array( [-7.6483764456387728, -9.8245764456387743, -10.528376445638774] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions\n",
    "\n",
    "Calculate the probability of a data instance belonging to each class value, and then we can look for the largest probability and return the associated class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "fc24369be7d0d5e24d636da8dd89190a",
     "grade": false,
     "grade_id": "predict_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def predict(summaries, input_array):\n",
    "    '''\n",
    "    Calculates the probability of each data instance belonging to each class value,\n",
    "    looks for the largest probability, and return the associated class.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    summaries: A dictionary of numpy arrays\n",
    "    input_array: A numpy array of instances; each instance is a numpy array of attributes\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A 1d numpy array\n",
    "    '''\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "\n",
    "    return best_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "c6418ffc4b4307130d82a033b269bba3",
     "grade": true,
     "grade_id": "predict_test",
     "locked": true,
     "points": 8,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "summaries_t = {0: np.array( [ (1, 0.5) ] ), 1: np.array( [ (20, 5.0) ] )}\n",
    "input_t1 = np.array( [[1.1]] )\n",
    "result_t1 = predict(summaries_t, input_t1)\n",
    "assert_array_equal(result_t1, np.array( [0.] ))\n",
    "\n",
    "test_set_t2 = np.array( [[1.1], [19.1]] )\n",
    "result_t2 = predict(summaries_t, test_set_t2)\n",
    "assert_array_equal(result_t2, np.array( [0., 1.] ))\n",
    "\n",
    "test_set_t3 = np.array( [[4], [.9], [0]] )\n",
    "result_t3 = predict(summaries_t, test_set_t3)\n",
    "assert_array_equal(result_t3, np.array( [1., 0., 0.] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you used Numpy correctly, it shouldn't be necessary to iterate over each test instance and make predictions. In other words, you don't have to use the `for` loop for `predict()`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

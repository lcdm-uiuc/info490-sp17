{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "1891bdcd87c6c960df75b6e90b02b234",
     "grade": false,
     "grade_id": "header",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "If you are not using the `Assignments` tab on the course JupyterHub server to read this notebook, read [Activating the assignments tab](https://github.com/lcdm-uiuc/info490-sp17/blob/master/help/act_assign_tab.md).\n",
    "\n",
    "A few things you should keep in mind when working on assignments:\n",
    "\n",
    "1. Make sure you fill in any place that says `YOUR CODE HERE`. Do **not** write your answer in anywhere else other than where it says `YOUR CODE HERE`. Anything you write anywhere else will be removed or overwritten by the autograder.\n",
    "\n",
    "2. Before you submit your assignment, make sure everything runs as expected. Go to menubar, select _Kernel_, and restart the kernel and run all cells (_Restart & Run all_).\n",
    "\n",
    "3. Do not change the title (i.e. file name) of this notebook.\n",
    "\n",
    "4. Make sure that you save your work (in the menubar, select _File_ â†’ _Save and CheckPoint_)\n",
    "\n",
    "5. You are allowed to submit an assignment multiple times, but only the most recent submission will be graded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "3c6835a355688b74636d278d9b4583a7",
     "grade": false,
     "grade_id": "title",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Problem 14.2. Spark DataFrames\n",
    "\n",
    "In this problem, we will use the Spark DataFrame to perform basic data processing tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "09582070780b81c48354fa0bd6a499a0",
     "grade": false,
     "grade_id": "import",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import StructField, StructType, IntegerType, FloatType, StringType\n",
    "import pandas as pd\n",
    "\n",
    "from nose.tools import assert_equal, assert_is_instance\n",
    "from pandas.util.testing import assert_frame_equal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e1f5217e4ddd480f583703de23206888",
     "grade": false,
     "grade_id": "markdown_1",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "We run Spark in [local mode](http://spark.apache.org/docs/latest/programming-guide.html#local-vs-cluster-modes) from within our Docker container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "b89f31e49fc9c87324f97bb9c08b5683",
     "grade": false,
     "grade_id": "sparkcontext",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "sc = SparkContext('local[*]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "67ce328656649298c3c32548e5b5e7eb",
     "grade": false,
     "grade_id": "markdown_2",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "We create a new RDD by reading in the data as a textfile. We use the ratings data from [MovieLens](http://grouplens.org/datasets/movielens/latest/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "21029810e4e5ce27067647f4aebddac2",
     "grade": false,
     "grade_id": "text_file",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "csv_path = '/home/data_scientist/data/ml-latest-small/ratings.csv'\n",
    "text_file = sc.textFile(csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c32f920d678f79b86f3e96c67162fbec",
     "grade": false,
     "grade_id": "markdown_3",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "- Write a function that creates a Spark DataFrame from `text_file`. For example, running\n",
    "\n",
    "```python\n",
    ">>> df = create_df(text_file)\n",
    ">>> df.show()\n",
    "```\n",
    "\n",
    "should give\n",
    "\n",
    "```\n",
    "+------+-------+------+----------+\n",
    "|userId|movieId|rating| timestamp|\n",
    "+------+-------+------+----------+\n",
    "|     1|     16|   4.0|1217897793|\n",
    "|     1|     24|   1.5|1217895807|\n",
    "|     1|     32|   4.0|1217896246|\n",
    "|     1|     47|   4.0|1217896556|\n",
    "|     1|     50|   4.0|1217896523|\n",
    "|     1|    110|   4.0|1217896150|\n",
    "|     1|    150|   3.0|1217895940|\n",
    "|     1|    161|   4.0|1217897864|\n",
    "|     1|    165|   3.0|1217897135|\n",
    "|     1|    204|   0.5|1217895786|\n",
    "|     1|    223|   4.0|1217897795|\n",
    "|     1|    256|   0.5|1217895764|\n",
    "|     1|    260|   4.5|1217895864|\n",
    "|     1|    261|   1.5|1217895750|\n",
    "|     1|    277|   0.5|1217895772|\n",
    "|     1|    296|   4.0|1217896125|\n",
    "|     1|    318|   4.0|1217895860|\n",
    "|     1|    349|   4.5|1217897058|\n",
    "|     1|    356|   3.0|1217896231|\n",
    "|     1|    377|   2.5|1217896373|\n",
    "+------+-------+------+----------+\n",
    "only showing top 20 rows\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "6ffbe4a649d91a4fab5a505aee4737fe",
     "grade": false,
     "grade_id": "create_df_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def create_df(rdd):\n",
    "    '''\n",
    "    Parameters\n",
    "    ----------\n",
    "    rdd: A pyspark.rdd.RDD instance.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A pyspark.sql.dataframe.DataFrame instance.\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "8e2ab8d3255817c670ecd5134912e71c",
     "grade": false,
     "grade_id": "create_df_run",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "df = create_df(text_file)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "5c6ecc823566ba447638654cdab8b59d",
     "grade": true,
     "grade_id": "create_df_test",
     "locked": true,
     "points": 30,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(df, pyspark.sql.dataframe.DataFrame)\n",
    "\n",
    "# convert the Spark dataframe to Pandas dataframe\n",
    "df_pd = pd.read_csv(csv_path)\n",
    "assert_frame_equal(df.toPandas(), df_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "903116df67525d9a9e9f183b1c0a442b",
     "grade": false,
     "grade_id": "markdown_4",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "- Select from the Spark DataFrame only the rows whose rating is greater than 3.\n",
    "- After filtering, return only two columns: `movieId` and `rating`.\n",
    "\n",
    "```python\n",
    ">>> favorable = filter_favorable_ratings(df)\n",
    ">>> favorable.show()\n",
    "```\n",
    "\n",
    "```\n",
    "+-------+------+\n",
    "|movieId|rating|\n",
    "+-------+------+\n",
    "|     16|   4.0|\n",
    "|     32|   4.0|\n",
    "|     47|   4.0|\n",
    "|     50|   4.0|\n",
    "|    110|   4.0|\n",
    "|    161|   4.0|\n",
    "|    223|   4.0|\n",
    "|    260|   4.5|\n",
    "|    296|   4.0|\n",
    "|    318|   4.0|\n",
    "|    349|   4.5|\n",
    "|    457|   4.0|\n",
    "|    480|   3.5|\n",
    "|    527|   4.5|\n",
    "|    589|   3.5|\n",
    "|    590|   3.5|\n",
    "|    593|   5.0|\n",
    "|    608|   3.5|\n",
    "|    648|   3.5|\n",
    "|    724|   3.5|\n",
    "+-------+------+\n",
    "only showing top 20 rows\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "6c2d97b1a17eec7e5b7318875f08fe2f",
     "grade": false,
     "grade_id": "filter_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def filter_favorable_ratings(df):\n",
    "    '''\n",
    "    Selects rows whose rating is greater than 3.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    A pyspark.sql.dataframe.DataFrame instance.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A pyspark.sql.dataframe.DataFrame instance.\n",
    "\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "f7295539d1855ea349884af46f089a02",
     "grade": false,
     "grade_id": "filter_run",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "favorable = filter_favorable_ratings(df)\n",
    "favorable.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "5fa5ac8250b97dddb79371c8680f8644",
     "grade": true,
     "grade_id": "filter_test",
     "locked": true,
     "points": 8,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(favorable, pyspark.sql.dataframe.DataFrame)\n",
    "\n",
    "favorable_pd = df_pd.loc[df_pd['rating'] > 3.0, ['movieId', 'rating']].reset_index(drop=True)\n",
    "assert_frame_equal(favorable.toPandas(), favorable_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "02c1c4f8f323bec7848c084876e5ce8f",
     "grade": false,
     "grade_id": "markdown_5",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "- Write a function that, given a `movieId`, computes the number of reviews for that movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "258baee60183857cf40c92a45a8a1be3",
     "grade": false,
     "grade_id": "find_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def find_n_reviews(df, movie_id):\n",
    "    '''\n",
    "    Finds the number of reviews for a movie.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    movie_id: An int.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    n_reviews: An int.\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return n_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "a07a035e0a6a7f3bb4a28f8698b98eb0",
     "grade": false,
     "grade_id": "find_run",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "n_toy_story = find_n_reviews(favorable, 1)\n",
    "print(n_toy_story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "67ded7423a25f9222cc1717244906774",
     "grade": true,
     "grade_id": "find_test",
     "locked": true,
     "points": 7,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(n_toy_story, int)\n",
    "\n",
    "test = [find_n_reviews(favorable, n) for n in range(1, 6)]\n",
    "test_pd = favorable_pd.groupby('movieId').size()[:5].tolist()\n",
    "assert_equal(test, test_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "1f1cbc95d6cc8f4d200a9e134233cb69",
     "grade": false,
     "grade_id": "markdown_6",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Cleanup\n",
    "\n",
    "We must stop the SparkContext in order to release the spark resources before existing this Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "ec8c059e7ca934a0d1fb3342fc042680",
     "grade": false,
     "grade_id": "sc_stop",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

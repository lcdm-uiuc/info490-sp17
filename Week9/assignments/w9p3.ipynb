{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 9 Problem 3\n",
    "\n",
    "If you are not using the `Assignments` tab on the course JupyterHub server to read this notebook, read [Activating the assignments tab](https://github.com/lcdm-uiuc/info490-sp17/blob/master/help/act_assign_tab.md).\n",
    "\n",
    "A few things you should keep in mind when working on assignments:\n",
    "\n",
    "1. Make sure you fill in any place that says `YOUR CODE HERE`. Do **not** write your answer in anywhere else other than where it says `YOUR CODE HERE`. Anything you write anywhere else will be removed or overwritten by the autograder.\n",
    "\n",
    "2. Before you submit your assignment, make sure everything runs as expected. Go to menubar, select _Kernel_, and restart the kernel and run all cells (_Restart & Run all_).\n",
    "\n",
    "3. Do not change the title (i.e. file name) of this notebook.\n",
    "\n",
    "4. Make sure that you save your work (in the menubar, select _File_  â†’ _Save and CheckPoint_)\n",
    "\n",
    "5. You are allowed to submit an assignment multiple times, but only the most recent submission will be graded.\n",
    "-----\n",
    "# Problem 9.3. NLP: Semantic Analysis\n",
    "In this problem, we explore semantic analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "7f833e774b49cba6ab19112f1806dc74",
     "grade": false,
     "grade_id": "import",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import time\n",
    "import numpy as np\n",
    "import gensim\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "\n",
    "from nose.tools import (\n",
    "    assert_equal,\n",
    "    assert_is_instance,\n",
    "    assert_almost_equal,\n",
    "    assert_true\n",
    "    )\n",
    "\n",
    "from numpy.testing import assert_array_equal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "\n",
    "# Wordnet\n",
    "We use the Wordnet synonym rings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "301a30c7a5990d75efe00f0ac5a0fe80",
     "grade": false,
     "grade_id": "wn",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Find how many entries a word has in the wordnet synset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "268af5336234bd7230849335c96da7d7",
     "grade": false,
     "grade_id": "e",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def find_number_of_entries(word):\n",
    "    '''\n",
    "    Finds the number of entries in the wordnet synset.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    word: A string.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    An int.\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "e94ac7b7795fa90ccf6c4fe2368c79b8",
     "grade": false,
     "grade_id": "print_e1",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "the_word = 'love'\n",
    "n_entries = find_number_of_entries(the_word)\n",
    "print('{0} total entries in synonym ring for {1}. '.format(n_entries, the_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "6044f7ab43772f05f37d873265e160bb",
     "grade": false,
     "grade_id": "print_e2",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "the_word = 'live'\n",
    "n_entries = find_number_of_entries(the_word)\n",
    "print('{0} total entries in synonym ring for {1}. '.format(n_entries, the_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "080261aa191ee8e0e98cd2f034432e48",
     "grade": true,
     "grade_id": "test_e",
     "locked": true,
     "points": 6,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(find_number_of_entries('love'), int)\n",
    "assert_equal(find_number_of_entries('love'), 10)\n",
    "assert_equal(find_number_of_entries('live'), 19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Similarities\n",
    "- Compute the path similarity for the input words. \n",
    "- Use the first noun synset (with number 01) for each word. \n",
    "- You could assume all input words have at least one noun synset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "7e728179c6c8e2be3e65198fa0aceff3",
     "grade": false,
     "grade_id": "ps",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def get_path_similarity(word1, word2):\n",
    "    '''\n",
    "    Computes the path similarity between word1 and word1.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    word1: A string.\n",
    "    word2: A string.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A float.\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "930b0c842a9447d0812150e2d28bd5d4",
     "grade": false,
     "grade_id": "print_ps",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Now we print similarity measures.\n",
    "fmt_str = '{1} to {2}: {0:4.3f}'\n",
    "\n",
    "print('Path Similarity:')\n",
    "print(40*'-')\n",
    "print(fmt_str.format(get_path_similarity('excess', 'surplus'), 'excess', 'surplus'))\n",
    "print(fmt_str.format(get_path_similarity('trade', 'economy'), 'trade', 'economy'))\n",
    "print(fmt_str.format(get_path_similarity('mean', 'average'), 'mean', 'average'))\n",
    "print(fmt_str.format(get_path_similarity('import', 'export'), 'mean', 'average'))\n",
    "print(fmt_str.format(get_path_similarity('excess', 'excess'), 'excess', 'excess'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "6a1abc56c348af477910131b7f05c6e2",
     "grade": true,
     "grade_id": "test_ps",
     "locked": true,
     "points": 6,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(get_path_similarity('excess', 'surplus'), float)\n",
    "assert_almost_equal(get_path_similarity('excess', 'surplus'), 1.0)\n",
    "assert_almost_equal(get_path_similarity('trade', 'economy'), 0.1)\n",
    "assert_almost_equal(get_path_similarity('mean', 'average'), 0.5)\n",
    "assert_almost_equal(get_path_similarity('import', 'export'), 0.3333333333333333)\n",
    "assert_almost_equal(get_path_similarity('excess', 'excess'), 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "# Word2Vec\n",
    "In the second half of this problem, we use the NLTK reuters corpus to build a word2vec model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "922c61e319a7630a87c63d3193f17741",
     "grade": false,
     "grade_id": "reuters",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import reuters\n",
    "sentences = reuters.sents()[:20000] # use a sample size smaller than corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec model\n",
    "- Build a Word2Vec model from sentences in the corpus.\n",
    "- Set the maximum distance between the current and predicted word within a sentence to 10.\n",
    "- Ignore all words with total frequency lower than 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "25d4bbc45b1b452c0c8d805d0ab73129",
     "grade": true,
     "grade_id": "model",
     "locked": true,
     "points": 7,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def get_model(sentences):\n",
    "    '''\n",
    "    Builds a Word2Vec model from sentences in corpus.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sentences: A list of lists(sentences); each sentence is a list of strings(words).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A Word2Vec instance.\n",
    "    '''\n",
    "    \n",
    "    ### BEGIN SOLUTIONS\n",
    "    model = gensim.models.Word2Vec(sentences, window=10, min_count=6)\n",
    "    ### END SOLUTIONS\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell would take about 30 seconds to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "5fa519b3ac0b1171ef27b0491680c6b9",
     "grade": false,
     "grade_id": "get_model",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "start_time = time.clock()\n",
    "model = get_model(sentences)\n",
    "print(time.clock() - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "c943099f3d1c2f3d15faf727df3d3a10",
     "grade": true,
     "grade_id": "test_model",
     "locked": true,
     "points": 7,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(model, gensim.models.Word2Vec)\n",
    "assert_equal(model.window, 10)\n",
    "assert_equal(model.min_count, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Similarity\n",
    "Compute Cosine Similarities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "be54f98b5144b47e534adf10c90715cf",
     "grade": false,
     "grade_id": "cs",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def get_cosine_similarity(model, word1, word2):\n",
    "    '''\n",
    "    Computes cosine similarity between \"word1\" and \"word2\" using a Word2Vec model.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model: A gensim.Word2Vec model.\n",
    "    word1: A string.\n",
    "    word2: A string.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A float.\n",
    "    '''\n",
    "    \n",
    "    ### BEGIN SOLUTIONS\n",
    "    similarity = model.similarity(word1, word2)\n",
    "    ### END SOLUTIONS\n",
    "    \n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "59a4ffb7d6cc3af6b68f30291c8de540",
     "grade": false,
     "grade_id": "print_cs",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Now we print similarity measures.\n",
    "fmt_str = '{1} to {2}: {0:4.3f}'\n",
    "\n",
    "print('Cosine Similarity:')\n",
    "print(40*'-')\n",
    "print(fmt_str.format(get_cosine_similarity(model, 'excess', 'surplus'), 'excess', 'surplus'))\n",
    "print(fmt_str.format(get_cosine_similarity(model, 'trade', 'economy'), 'trade', 'economy'))\n",
    "print(fmt_str.format(get_cosine_similarity(model, 'mean', 'average'), 'mean', 'average'))\n",
    "print(fmt_str.format(get_cosine_similarity(model, 'import', 'export'), 'mean', 'average'))\n",
    "print(fmt_str.format(get_cosine_similarity(model, 'excess', 'excess'), 'excess', 'excess'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "dae9791c2dbb7c81df4d8a9d61df26fa",
     "grade": true,
     "grade_id": "test_cs",
     "locked": true,
     "points": 7,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(get_cosine_similarity(model, 'excess', 'surplus'), float)\n",
    "assert_almost_equal(get_cosine_similarity(model, 'excess', 'surplus'), model.similarity('excess', 'surplus'))\n",
    "assert_almost_equal(get_cosine_similarity(model, 'trade', 'economy'), model.similarity('trade', 'economy'))\n",
    "assert_almost_equal(get_cosine_similarity(model, 'mean', 'average'), model.similarity('mean', 'average'))\n",
    "assert_almost_equal(get_cosine_similarity(model, 'import', 'export'), model.similarity('import', 'export'))\n",
    "assert_almost_equal(get_cosine_similarity(model, 'excess', 'excess'), 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most similar words\n",
    "Find the top 5 most similar words, where \"price\", \"economy\", and \"trade\" contribute positively towards the similarity, and \"law\" and \"legal\" contribute negatively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "eca3bba6595875eb5a0264fdf2981520",
     "grade": false,
     "grade_id": "sw",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def find_most_similar_words(model):\n",
    "    '''\n",
    "    Find the top 5 most similar words,\n",
    "    where \"price\", \"economy\", and \"trade\" contribute positively towards the similarity,\n",
    "    and \"law\" and \"legal\" contribute negatively.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model: A gensim.Word2Vec model.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A list of tuples (word, similarty).\n",
    "    word: A string.\n",
    "    similarity: A float.\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "53f1744adf051f6f8189035db5ef5786",
     "grade": false,
     "grade_id": "print_sw",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print('{0:14s}: {1}'.format('Word', 'Cosine Similarity'))\n",
    "print(40*'-')\n",
    "for val in find_most_similar_words(model):\n",
    "    print('{0:14s}: {1:6.3f}'.format(val[0], val[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "daa789536cbd4ba2cc34fd919fd87d3d",
     "grade": true,
     "grade_id": "test_sw",
     "locked": true,
     "points": 7,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(find_most_similar_words(model), list)\n",
    "assert_true(all(isinstance(t[0], str) for t in find_most_similar_words(model)))\n",
    "assert_true(all(isinstance(t[1], float) for t in find_most_similar_words(model)))\n",
    "assert_equal(len(find_most_similar_words(model)), 5)\n",
    "words = [t[0] for t in model.most_similar(positive=['price', 'economy', 'trade'], negative=['law', 'legal'], topn=5)]\n",
    "similarities = [t[1] for t in model.most_similar(positive=['price', 'economy', 'trade'], negative=['law', 'legal'], topn=5)]\n",
    "assert_equal([t[0] for t in find_most_similar_words(model)], words)\n",
    "assert_almost_equal(find_most_similar_words(model)[0][1], similarities[0])\n",
    "assert_almost_equal(find_most_similar_words(model)[1][1], similarities[1])\n",
    "assert_almost_equal(find_most_similar_words(model)[2][1], similarities[2])\n",
    "assert_almost_equal(find_most_similar_words(model)[3][1], similarities[3])\n",
    "assert_almost_equal(find_most_similar_words(model)[4][1], similarities[4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
